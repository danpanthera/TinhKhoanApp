import { formatFileSize } from '../utils/numberFormatter.js'
import apiClient from './api.js'

/**
 * Smart Data Import Service - Handles intelligent file upload with automatic categorization
 * Sá»­ dá»¥ng API SmartDataImport Ä‘á»ƒ tá»± Ä‘á»™ng phÃ¢n loáº¡i vÃ  import dá»¯ liá»‡u
 * Há»— trá»£ chunked upload cho file lá»›n vÃ  progress tracking
 */
class SmartImportService {
  constructor() {
    // Cáº¥u hÃ¬nh chunked upload cho file siÃªu lá»›n 2GB
    this.CHUNK_SIZE = 1024 * 1024 * 10 // 10MB má»—i chunk (tÄƒng tá»« 5MB Ä‘á»ƒ upload nhanh hÆ¡n)
    this.MAX_FILE_SIZE = 1024 * 1024 * 1024 * 2 // 2GB max file size
    this.LARGE_FILE_THRESHOLD = 1024 * 1024 * 50 // 50MB Ä‘á»ƒ quyáº¿t Ä‘á»‹nh cÃ³ dÃ¹ng chunked upload
  }

  /**
   * Upload file vá»›i Smart Import - tá»± Ä‘á»™ng phÃ¢n loáº¡i dá»±a vÃ o filename
   * @param {File} file - File cáº§n upload
   * @param {Date} statementDate - NgÃ y sao kÃª (tÃ¹y chá»n)
   * @param {Function} progressCallback - Callback Ä‘á»ƒ track progress
   * @returns {Promise} Káº¿t quáº£ upload vÃ  xá»­ lÃ½
   */
  async uploadSmartFile(file, statementDate = null, progressCallback = null) {
    try {
      // Validation file size
      if (file.size > this.MAX_FILE_SIZE) {
        throw new Error(
          `File ${file.name} quÃ¡ lá»›n (${formatFileSize(file.size)}). Giá»›i háº¡n tá»‘i Ä‘a: ${formatFileSize(this.MAX_FILE_SIZE)}`,
        )
      }

      // Quyáº¿t Ä‘á»‹nh dÃ¹ng chunked upload hay normal upload
      if (file.size > this.LARGE_FILE_THRESHOLD) {
        console.log(`ðŸ“¦ Using chunked upload for large file: ${file.name} (${formatFileSize(file.size)})`)
        return await this.uploadLargeFile(file, statementDate, progressCallback)
      } else {
        console.log(`ðŸ“¤ Using normal upload for file: ${file.name} (${formatFileSize(file.size)})`)
        return await this.uploadNormalFile(file, statementDate, progressCallback)
      }
    } catch (error) {
      // Log chi tiáº¿t lá»—i 400 tá»« backend Ä‘á»ƒ dá»… debug
      if (error.response) {
        const { status, data } = error.response
        console.error('ðŸ”¥ Smart Import upload error (response):', status, data)
        if (status === 400 && data && (data.errors || data.title)) {
          const detail = data.errors ? JSON.stringify(data.errors) : data.title
          throw new Error(`Smart Import failed (400): ${detail}`)
        }
      } else if (error.request) {
        console.error('ðŸ”¥ Smart Import upload error (no response): server khÃ´ng pháº£n há»“i')
      } else {
        console.error('ðŸ”¥ Smart Import upload error (setup):', error.message)
      }
      throw new Error(`Smart Import failed: ${error.response?.data?.message || error.message}`)
    }
  }

  /**
   * Upload file thÃ´ng thÆ°á»ng (nhá» hÆ¡n 10MB) - OPTIMIZED
   */
  async uploadNormalFile(file, statementDate = null, progressCallback = null) {
    const formData = new FormData()
    formData.append('file', file)

    // ThÃªm statement date náº¿u cÃ³
    if (statementDate) {
      formData.append('statementDate', statementDate.toISOString())
    }

    const response = await apiClient.post('/DirectImport/smart', formData, {
      // KhÃ´ng set 'Content-Type' Ä‘á»ƒ axios/browser tá»± thÃªm boundary cho FormData
      timeout: 1200000, // ðŸš€ TÄƒng lÃªn 20 phÃºt cho GL01 large files (was 5 minutes)
      onUploadProgress: progressEvent => {
        if (progressCallback && progressEvent.total) {
          const percentCompleted = Math.round((progressEvent.loaded * 100) / progressEvent.total)
          progressCallback({
            loaded: progressEvent.loaded,
            total: progressEvent.total,
            percentage: percentCompleted,
            stage: 'uploading',
          })
        }
      },
    })

    return response.data
  }

  /**
   * Upload file lá»›n vá»›i chunked upload - OPTIMIZED
   */
  async uploadLargeFile(file, statementDate = null, progressCallback = null) {
    // TODO: Implement true chunked upload when backend supports it
    // For now, use optimized upload with extended timeout
    const formData = new FormData()
    formData.append('file', file)

    if (statementDate) {
      formData.append('statementDate', statementDate.toISOString())
    }

    const response = await apiClient.post('/DirectImport/smart', formData, {
      // KhÃ´ng set 'Content-Type' Ä‘á»ƒ axios/browser tá»± thÃªm boundary cho FormData
      timeout: 1800000, // ðŸš€ TÄƒng lÃªn 30 phÃºt cho file siÃªu lá»›n (GL01 162MB) - was 10 minutes
      onUploadProgress: progressEvent => {
        if (progressCallback && progressEvent.total) {
          const percentCompleted = Math.round((progressEvent.loaded * 100) / progressEvent.total)
          progressCallback({
            loaded: progressEvent.loaded,
            total: progressEvent.total,
            percentage: percentCompleted,
            stage: 'uploading',
          })
        }
      },
    })

    return response.data
  }

  // Loáº¡i bá» method formatFileSize cÅ© vÃ¬ Ä‘Ã£ import tá»« numberFormatter
  // formatFileSize() method removed - using imported utility

  /**
   * Upload nhiá»u file vá»›i Smart Import - OPTIMIZED PARALLEL VERSION
   * @param {FileList|Array} files - Danh sÃ¡ch file cáº§n upload
   * @param {Date} statementDate - NgÃ y sao kÃª (tÃ¹y chá»n)
   * @param {Function} progressCallback - Callback Ä‘á»ƒ track progress tá»•ng thá»ƒ
   * @returns {Promise} Káº¿t quáº£ upload batch
   */
  async uploadSmartFiles(files, statementDate = null, progressCallback = null) {
    try {
  const totalFiles = files.length
  // Háº¡n cháº¿ song song Ä‘á»ƒ trÃ¡nh quÃ¡ táº£i DB vÃ  lá»—i káº¿t ná»‘i khi login (TCP Provider)
  const MAX_CONCURRENT_UPLOADS = 2

      console.log(
        `ðŸš€ Starting PARALLEL Smart Import with ${totalFiles} files (max ${MAX_CONCURRENT_UPLOADS} concurrent)`,
      )

      // ðŸ“Š Tracking variables
      const results = []
      const progressTracking = new Map() // Track progress cá»§a tá»«ng file
      let completedCount = 0

      // Update overall progress function
      const updateOverallProgress = () => {
        const totalProgress = Array.from(progressTracking.values()).reduce((sum, progress) => sum + progress, 0)
        const overallPercentage = Math.round(totalProgress / totalFiles)

        if (progressCallback) {
          const currentFiles = Array.from(progressTracking.keys()).filter(
            fileName => progressTracking.get(fileName) < 100,
          )

          progressCallback({
            current: completedCount,
            total: totalFiles,
            percentage: overallPercentage,
            currentFile: currentFiles.length > 0 ? `${currentFiles.length} file(s) Ä‘ang upload...` : 'HoÃ n thÃ nh',
            stage: completedCount === totalFiles ? 'completed' : 'uploading',
            activeFiles: currentFiles.length,
          })
        }
      }

      // ðŸš€ Create upload promises vá»›i concurrency control
      const uploadFile = async (file, index) => {
        try {
          // Initialize progress tracking
          progressTracking.set(file.name, 0)

          // Progress callback cho tá»«ng file
          const fileProgressCallback = fileProgress => {
            progressTracking.set(file.name, fileProgress.percentage)
            updateOverallProgress()
          }

          const result = await this.uploadSmartFile(file, statementDate, fileProgressCallback)

          // Mark as completed
          progressTracking.set(file.name, 100)
          completedCount++

          console.log(`âœ… Successfully uploaded: ${file.name} (${completedCount}/${totalFiles})`)

          return {
            fileName: file.name,
            success: true,
            result: result,
            index: index + 1,
            fileSize: file.size,
          }
        } catch (error) {
          completedCount++
          console.error(`âŒ Failed to upload: ${file.name}`, error)

          return {
            fileName: file.name,
            success: false,
            error: error.message,
            index: index + 1,
            fileSize: file.size,
          }
        }
      }

      // ï¿½ LIMITED CONCURRENCY: process with a small pool and jitter to protect backend
      console.log(`ðŸš¦ Using limited concurrency processing (max ${MAX_CONCURRENT_UPLOADS})`)

      const queue = Array.from(files)
      const resultsTemp = []

      const next = async () => {
        if (queue.length === 0) return
        const file = queue.shift()
        const index = totalFiles - queue.length - 1
        try {
          const res = await uploadFile(file, index)
          resultsTemp.push({ status: 'fulfilled', value: res, index })
        } catch (err) {
          resultsTemp.push({ status: 'rejected', reason: err, index })
        } finally {
          // small jitter between tasks to avoid thundering herd
          await new Promise(r => setTimeout(r, 300))
          if (queue.length > 0) await next()
        }
      }

      const workers = Array.from({ length: Math.min(MAX_CONCURRENT_UPLOADS, totalFiles) }, () => next())
      await Promise.all(workers)

      // Map results to settled format
      const settledResults = resultsTemp

      // Extract results from settled promises
      settledResults.forEach((settled, index) => {
        if (settled.status === 'fulfilled') {
          results.push(settled.value)
        } else {
          results.push({
            fileName: files[index]?.name || 'unknown',
            success: false,
            error: settled.reason?.message || 'Unknown error',
            index: index + 1,
            fileSize: files[index]?.size || 0,
          })
        }
      })

      // Final progress update
      if (progressCallback) {
        progressCallback({
          current: totalFiles,
          total: totalFiles,
          percentage: 100,
          currentFile: 'HoÃ n thÃ nh táº¥t cáº£',
          stage: 'completed',
          activeFiles: 0,
        })
      }

      const successCount = results.filter(r => r.success).length
      const failureCount = results.filter(r => !r.success).length

      console.log(`ðŸ TRUE PARALLEL Smart Import completed: ${successCount}/${totalFiles} successful`)

      return {
        totalFiles: totalFiles,
        successCount: successCount,
        failureCount: failureCount,
        results: results,
        totalSize: Array.from(files).reduce((sum, file) => sum + file.size, 0),
        uploadMethod: 'true-parallel',
        maxConcurrency: 'unlimited',
      }
    } catch (error) {
      console.error('ðŸ”¥ Smart Import batch upload error:', error)
      throw new Error(`Smart Import batch failed: ${error.message}`)
    }
  }

  /**
   * Láº¥y danh sÃ¡ch file Ä‘Ã£ upload vÃ  káº¿t quáº£ xá»­ lÃ½
   * @returns {Promise} Danh sÃ¡ch import records
   */
  async getImportedRecords() {
    try {
      const response = await apiClient.get('/SmartDataImport/imported-records')
      return response.data
    } catch (error) {
      console.error('ðŸ”¥ Error fetching imported records:', error)
      throw new Error(`Fetch imported records failed: ${error.response?.data?.message || error.message}`)
    }
  }

  /**
   * Láº¥y chi tiáº¿t má»™t import record
   * @param {number} recordId - ID cá»§a import record
   * @returns {Promise} Chi tiáº¿t import record
   */
  async getImportedRecordDetail(recordId) {
    try {
      const response = await apiClient.get(`/SmartDataImport/imported-records/${recordId}`)
      return response.data
    } catch (error) {
      console.error('ðŸ”¥ Error fetching import record detail:', error)
      throw new Error(`Fetch import record detail failed: ${error.response?.data?.message || error.message}`)
    }
  }

  /**
   * Process imported data to history tables (move to raw data tables)
   * @param {number} recordId - ID cá»§a import record
   * @param {string} category - Category cá»§a data
   * @param {Date} statementDate - NgÃ y sao kÃª
   * @returns {Promise} Káº¿t quáº£ processing
   */
  async processToHistoryTables(recordId, category, statementDate = null) {
    try {
      const payload = {
        importedDataRecordId: recordId,
        category: category,
      }

      if (statementDate) {
        payload.statementDate = statementDate.toISOString()
      }

      const response = await apiClient.post('/SmartDataImport/process-to-history', payload)
      return response.data
    } catch (error) {
      console.error('ðŸ”¥ Error processing to history tables:', error)
      throw new Error(`Process to history failed: ${error.response?.data?.message || error.message}`)
    }
  }

  /**
   * Validate category support
   * @returns {Promise} Danh sÃ¡ch category Ä‘Æ°á»£c há»— trá»£
   */
  async getSupportedCategories() {
    try {
      const response = await apiClient.get('/SmartDataImport/supported-categories')
      return response.data
    } catch (error) {
      console.error('ðŸ”¥ Error fetching supported categories:', error)
      return ['DP01', 'LN01', 'LN03', 'GL01', 'GL41', 'DPDA', 'EI01', 'RR01'] // fallback
    }
  }

  /**
   * Tá»± Ä‘á»™ng detect category tá»« filename
   * @param {string} fileName - TÃªn file
   * @returns {string} Category Ä‘Æ°á»£c detect
   */
  detectCategoryFromFileName(fileName) {
    const upperFileName = fileName.toUpperCase()

    // Pattern matching for different data types
    const patterns = {
      DP01: /DP01|DEPOSIT|TIENGUI/,
      LN01: /LN01|LOAN|CHOAVAY/,
      LN03: /LN03|LOAN.*CLASSIFY|PHANLOAINO/,
      GL01: /GL01|GENERAL.*LEDGER|SOTONGOHAP/,
      GL41: /GL41|BALANCE|BANGSODUE/,
      DPDA: /DPDA|DEPOSIT.*DETAIL|CHITIETTIENGUI/,
      EI01: /EI01|INCOME|THUNHAP/,
      RR01: /RR01|RATIO|TYLE/,
    }

    for (const [category, pattern] of Object.entries(patterns)) {
      if (pattern.test(upperFileName)) {
        return category
      }
    }

    return 'UNKNOWN'
  }

  /**
   * Extract NgayDL from filename
   * @param {string} fileName - TÃªn file
   * @returns {Date|null} NgÃ y DL Ä‘Æ°á»£c extract
   */
  extractDateFromFileName(fileName) {
    const patterns = [
      /(\d{4})(\d{2})(\d{2})/, // YYYYMMDD
      /(\d{2})(\d{2})(\d{4})/, // DDMMYYYY
      /(\d{4})-(\d{2})-(\d{2})/, // YYYY-MM-DD
      /(\d{2})-(\d{2})-(\d{4})/, // DD-MM-YYYY
    ]

    for (const pattern of patterns) {
      const match = fileName.match(pattern)
      if (match) {
        let year, month, day
        if (pattern.source.includes('(\\d{4})') && match[1].length === 4) {
          // YYYY first
          year = parseInt(match[1])
          month = parseInt(match[2])
          day = parseInt(match[3])
        } else {
          // DD first
          day = parseInt(match[1])
          month = parseInt(match[2])
          year = parseInt(match[3])
        }

        if (year > 2000 && year < 2100 && month >= 1 && month <= 12 && day >= 1 && day <= 31) {
          return new Date(year, month - 1, day)
        }
      }
    }

    return null
  }
}

// Export singleton instance
export default new SmartImportService()
