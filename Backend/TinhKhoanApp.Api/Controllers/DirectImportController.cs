using TinhKhoanApp.Api.Models.Common;
using Microsoft.AspNetCore.Mvc;
using TinhKhoanApp.Api.Models;
using TinhKhoanApp.Api.Services.Interfaces;
using Microsoft.AspNetCore.WebUtilities;
using Microsoft.Net.Http.Headers;
using System.Threading.Channels;
using TinhKhoanApp.Api.Helpers;
using TinhKhoanApp.Api.Data;
using Microsoft.EntityFrameworkCore;

namespace TinhKhoanApp.Api.Controllers
{
    /// <summary>
    /// Controller cho Direct Import - Import tr·ª±c ti·∫øp v√†o b·∫£ng ri√™ng bi·ªát
    /// Hi·ªáu nƒÉng cao v·ªõi SqlBulkCopy, b·ªè qua c√°c b∆∞·ªõc x·ª≠ l√Ω trung gian
    /// </summary>
    [ApiController]
    [Route("api/[controller]")]
    public class DirectImportController : ControllerBase
    {
        private readonly IDirectImportService _directImportService;
        private readonly ILogger<DirectImportController> _logger;
        private readonly ApplicationDbContext _context;

        /// <summary>
        /// Constructor
        /// </summary>
        public DirectImportController(
            IDirectImportService directImportService,
            ILogger<DirectImportController> logger,
            ApplicationDbContext context)
        {
            _directImportService = directImportService;
            _logger = logger;
            _context = context;
        }

        /// <summary>
        /// Import th√¥ng minh - t·ª± ƒë·ªông ph√°t hi·ªán lo·∫°i file v√† import tr·ª±c ti·∫øp
        /// </summary>
        /// <param name="file">File d·ªØ li·ªáu CSV/Excel</param>
        /// <param name="statementDate">Ng√†y b√°o c√°o (optional)</param>
        /// <returns>K·∫øt qu·∫£ import v·ªõi th√¥ng tin chi ti·∫øt</returns>
        [HttpPost("smart")]
        [DisableRequestSizeLimit]
        public async Task<ActionResult<object>> ImportSmartDirect(
            IFormFile file,
            [FromQuery] string? statementDate = null)
        {
            try
            {
                if (file == null || file.Length == 0)
                {
                    return BadRequest("File kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng");
                }

                // üéØ AUTO-ROUTE GL01 to OPTIMIZED WORKFLOW
                var dataType = _directImportService.DetectDataTypeFromFileName(file.FileName);
                if (dataType == "GL01")
                {
                    _logger.LogInformation("üîÑ [SMART_ROUTING] Auto-routing GL01 to optimized workflow: {FileName}", file.FileName);
                    var optimizedResult = await OptimizedGL01Import(file, statementDate);
                    return optimizedResult;
                }

                _logger.LogInformation("üöÄ [DIRECT_IMPORT_API] Smart import start: {FileName}, Size: {FileSize}MB",
                    file.FileName, file.Length / 1024.0 / 1024.0);

                var result = await _directImportService.ImportSmartDirectAsync(file, statementDate);

                if (result.Success)
                {
                    _logger.LogInformation("‚úÖ [DIRECT_IMPORT_API] Smart import success: {Records} records in {Duration}ms",
                        result.ProcessedRecords, result.Duration.TotalMilliseconds);
                    return Ok(result);
                }
                else
                {
                    _logger.LogError("‚ùå [DIRECT_IMPORT_API] Smart import failed: {Error}", result.ErrorMessage);
                    return BadRequest(result);
                }
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "üí• [DIRECT_IMPORT_API] Smart import exception: {FileName}", file?.FileName);
                return StatusCode(500, new DirectImportResult
                {
                    Success = false,
                    ErrorMessage = $"L·ªói h·ªá th·ªëng: {ex.Message}",
                    FileName = file?.FileName ?? "Unknown"
                });
            }
        }

        /// <summary>
        /// üöÄ SMART GL01 IMPORT - T·ª± ƒë·ªông qu·∫£n l√Ω columnstore index cho optimal performance
        /// Workflow: Disable columnstore ‚Üí Import ‚Üí Re-enable columnstore
        /// </summary>
        /// <param name="file">File GL01 CSV</param>
        /// <param name="statementDate">Ng√†y b√°o c√°o (optional)</param>
        /// <param name="skipColumnstoreManagement">B·ªè qua t·ª± ƒë·ªông qu·∫£n l√Ω columnstore index</param>
        /// <returns>K·∫øt qu·∫£ import v·ªõi th√¥ng tin chi ti·∫øt v·ªÅ performance</returns>
        [HttpPost("smart-gl01")]
        [DisableRequestSizeLimit]
        public async Task<ActionResult<object>> SmartGL01Import(
            IFormFile file,
            [FromQuery] string? statementDate = null,
            [FromQuery] bool skipColumnstoreManagement = false)
        {
            var performanceLog = new List<string>();
            var startTime = DateTime.Now;

            try
            {
                if (file == null || file.Length == 0)
                {
                    return BadRequest("File kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng");
                }

                // Detect data type
                var dataType = _directImportService.DetectDataTypeFromFileName(file.FileName);
                if (dataType != "GL01")
                {
                    return BadRequest($"File kh√¥ng ph·∫£i GL01. Detected type: {dataType}. S·ª≠ d·ª•ng endpoint /smart cho c√°c lo·∫°i file kh√°c.");
                }

                var fileSizeMB = file.Length / 1024.0 / 1024.0;
                var isLargeFile = fileSizeMB > 10; // Files > 10MB ƒë∆∞·ª£c coi l√† l·ªõn

                _logger.LogInformation("üöÄ [SMART_GL01] Starting smart GL01 import: {FileName}, Size: {FileSize}MB, Large: {IsLarge}",
                    file.FileName, fileSizeMB, isLargeFile);

                performanceLog.Add($"‚è±Ô∏è Start time: {startTime:HH:mm:ss.fff}");
                performanceLog.Add($"üìÇ File: {file.FileName} ({fileSizeMB:F2} MB)");
                performanceLog.Add($"üìä Large file mode: {isLargeFile}");

                bool columnstoreWasDisabled = false;
                bool columnstoreExisted = false;

                // STEP 1: Check v√† disable columnstore index n·∫øu c·∫ßn
                if (!skipColumnstoreManagement && isLargeFile)
                {
                    var checkIndexTime = DateTime.Now;
                    var indexInfo = await CheckGL01IndexesInternal();
                    columnstoreExisted = indexInfo.Any(i => i.IndexType?.Contains("COLUMNSTORE") == true);

                    if (columnstoreExisted)
                    {
                        performanceLog.Add($"üîç Found columnstore index at {checkIndexTime:HH:mm:ss.fff}");

                        var disableTime = DateTime.Now;
                        await DisableColumnstoreIndexInternal();
                        columnstoreWasDisabled = true;

                        performanceLog.Add($"üîß Disabled columnstore at {disableTime:HH:mm:ss.fff} (took {(DateTime.Now - disableTime).TotalMilliseconds:F0}ms)");
                        _logger.LogInformation("üîß [SMART_GL01] Disabled columnstore index for large file import");
                    }
                    else
                    {
                        performanceLog.Add($"‚úÖ No columnstore index found - proceeding with normal import");
                    }
                }

                // STEP 2: Perform the actual import
                var importStartTime = DateTime.Now;
                performanceLog.Add($"üöÄ Starting import at {importStartTime:HH:mm:ss.fff}");

                var result = await _directImportService.ImportSmartDirectAsync(file, statementDate);

                var importEndTime = DateTime.Now;
                var importDuration = importEndTime - importStartTime;
                performanceLog.Add($"‚úÖ Import completed at {importEndTime:HH:mm:ss.fff} (took {importDuration.TotalSeconds:F2}s)");

                // STEP 3: Re-enable columnstore index n·∫øu ƒë√£ disable
                if (columnstoreWasDisabled && !skipColumnstoreManagement)
                {
                    var enableStartTime = DateTime.Now;
                    performanceLog.Add($"üîÑ Re-enabling columnstore at {enableStartTime:HH:mm:ss.fff}");

                    // Enable columnstore trong background ƒë·ªÉ kh√¥ng block response
                    _ = Task.Run(async () =>
                    {
                        try
                        {
                            await EnableColumnstoreIndexInternal();
                            var enableEndTime = DateTime.Now;
                            _logger.LogInformation("üîß [SMART_GL01] Re-enabled columnstore index in background (took {Duration}ms)",
                                (enableEndTime - enableStartTime).TotalMilliseconds);
                        }
                        catch (Exception ex)
                        {
                            _logger.LogError(ex, "‚ùå [SMART_GL01] Failed to re-enable columnstore index in background");
                        }
                    });

                    performanceLog.Add($"üîÑ Columnstore re-enable started in background");
                }

                var totalTime = DateTime.Now - startTime;
                performanceLog.Add($"üèÅ Total workflow time: {totalTime.TotalSeconds:F2}s");

                if (result.Success)
                {
                    var response = new
                    {
                        Success = result.Success,
                        FileName = result.FileName,
                        DataType = result.DataType,
                        TargetTable = result.TargetTable,
                        FileSizeBytes = result.FileSizeBytes,
                        FileSizeMB = fileSizeMB,
                        ProcessedRecords = result.ProcessedRecords,
                        ErrorRecords = result.ErrorRecords,
                        NgayDL = result.NgayDL,
                        BatchId = result.BatchId,
                        ImportedDataRecordId = result.ImportedDataRecordId,
                        StartTime = result.StartTime,
                        EndTime = result.EndTime,
                        Duration = result.Duration,
                        RecordsPerSecond = result.RecordsPerSecond,
                        MBPerSecond = result.MBPerSecond,

                        // Smart workflow specific info
                        SmartWorkflow = new
                        {
                            IsLargeFile = isLargeFile,
                            ColumnstoreManagement = new
                            {
                                Enabled = !skipColumnstoreManagement,
                                ColumnstoreExisted = columnstoreExisted,
                                WasDisabled = columnstoreWasDisabled,
                                ReEnabledInBackground = columnstoreWasDisabled
                            },
                            TotalWorkflowTime = totalTime,
                            ImportOnlyTime = importDuration,
                            PerformanceLog = performanceLog
                        }
                    };

                    _logger.LogInformation("‚úÖ [SMART_GL01] Workflow completed successfully: {Records} records in {Duration}ms",
                        result.ProcessedRecords, totalTime.TotalMilliseconds);

                    return Ok(response);
                }
                else
                {
                    _logger.LogError("‚ùå [SMART_GL01] Import failed: {Error}", result.ErrorMessage);
                    return BadRequest(new
                    {
                        Success = false,
                        Error = result.ErrorMessage,
                        SmartWorkflow = new { PerformanceLog = performanceLog }
                    });
                }
            }
            catch (Exception ex)
            {
                var errorTime = DateTime.Now;
                performanceLog.Add($"üí• Error at {errorTime:HH:mm:ss.fff}: {ex.Message}");

                _logger.LogError(ex, "üí• [SMART_GL01] Smart workflow exception: {FileName}", file?.FileName);
                return StatusCode(500, new
                {
                    Success = false,
                    Error = $"L·ªói h·ªá th·ªëng: {ex.Message}",
                    FileName = file?.FileName ?? "Unknown",
                    SmartWorkflow = new { PerformanceLog = performanceLog }
                });
            }
        }

        /// <summary>
        /// Import tr·ª±c ti·∫øp file DP01 v√†o b·∫£ng DP01
        /// </summary>
        [HttpPost("dp01")]
        [DisableRequestSizeLimit]
        public async Task<ActionResult<DirectImportResult>> ImportDP01Direct(
            IFormFile file,
            [FromQuery] string? statementDate = null)
        {
            try
            {
                if (file == null || file.Length == 0)
                {
                    return BadRequest("File kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng");
                }

                _logger.LogInformation("üöÄ [DP01_DIRECT_API] Import start: {FileName}", file.FileName);

                var result = await _directImportService.ImportDP01DirectAsync(file, statementDate);

                if (result.Success)
                {
                    _logger.LogInformation("‚úÖ [DP01_DIRECT_API] Import success: {Records} records", result.ProcessedRecords);
                    return Ok(result);
                }
                else
                {
                    _logger.LogError("‚ùå [DP01_DIRECT_API] Import failed: {Error}", result.ErrorMessage);
                    return BadRequest(result);
                }
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "üí• [DP01_DIRECT_API] Import exception: {FileName}", file?.FileName);
                return StatusCode(500, new DirectImportResult
                {
                    Success = false,
                    ErrorMessage = $"L·ªói h·ªá th·ªëng: {ex.Message}",
                    FileName = file?.FileName ?? "Unknown"
                });
            }
        }

        /// <summary>
        /// Import tr·ª±c ti·∫øp file LN01 v√†o b·∫£ng LN01
        /// </summary>
        [HttpPost("ln01")]
        [DisableRequestSizeLimit]
        public async Task<ActionResult<DirectImportResult>> ImportLN01Direct(
            IFormFile file,
            [FromQuery] string? statementDate = null)
        {
            try
            {
                if (file == null || file.Length == 0)
                {
                    return BadRequest("File kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng");
                }

                var result = await _directImportService.ImportLN01DirectAsync(file, statementDate);
                return result.Success ? Ok(result) : BadRequest(result);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "üí• [LN01_DIRECT_API] Import exception: {FileName}", file?.FileName);
                return StatusCode(500, new DirectImportResult
                {
                    Success = false,
                    ErrorMessage = $"L·ªói h·ªá th·ªëng: {ex.Message}",
                    FileName = file?.FileName ?? "Unknown"
                });
            }
        }

        /// <summary>
        /// L·∫•y th√¥ng tin tr·∫°ng th√°i import
        /// </summary>
        [HttpGet("status")]
        public async Task<ActionResult<object>> GetImportStatus()
        {
            try
            {
                // TODO: Implement status tracking
                return Ok(new
                {
                    Status = "Direct Import System Online",
                    Version = "1.0.0",
                    Features = new[]
                    {
                        "‚úÖ Smart Detection - T·ª± ƒë·ªông ph√°t hi·ªán lo·∫°i file",
                        "‚úÖ SqlBulkCopy - TƒÉng t·ªëc import 2-5x",
                        "‚úÖ Temporal Tables - L·ªãch s·ª≠ thay ƒë·ªïi t·ª± ƒë·ªông",
                        "‚úÖ Columnstore Indexes - Hi·ªáu nƒÉng query 10-100x",
                        "‚úÖ Metadata Tracking - Ch·ªâ l∆∞u metadata, kh√¥ng l∆∞u raw data"
                    },
                    SupportedDataTypes = new[]
                    {
                        "DP01 - B√°o c√°o t√†i ch√≠nh",
                        "LN01 - D·ªØ li·ªáu cho vay",
                        "GL01 - D·ªØ li·ªáu s·ªï c√°i",
                        "GL41 - D·ªØ li·ªáu giao d·ªãch",
                        "DPDA - D·ªØ li·ªáu ph√¢n t√≠ch",
                        "EI01 - D·ªØ li·ªáu l√£i su·∫•t",
                        "RR01 - D·ªØ li·ªáu r·ªßi ro",
                    }
                });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "üí• [DIRECT_IMPORT_API] Status check exception");
                return StatusCode(500, new { Error = ex.Message });
            }
        }

        /// <summary>
        /// L·∫•y s·ªë l∆∞·ª£ng records th·ª±c t·∫ø t·ª´ database tables (kh√¥ng ph·∫£i metadata)
        /// </summary>
        [HttpGet("table-counts")]
        public async Task<ActionResult<Dictionary<string, int>>> GetTableCounts()
        {
            try
            {
                _logger.LogInformation("üìä Getting actual table record counts");

                var counts = await _directImportService.GetTableRecordCountsAsync();

                return Ok(counts);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå Error getting table counts");
                return StatusCode(500, new { Error = ex.Message });
            }
        }

        /// <summary>
        /// üöÄ STREAMING UPLOAD - Import file l·ªõn b·∫±ng streaming (h√†ng trƒÉm MB)
        /// Kh√¥ng load to√†n b·ªô file v√†o memory, stream tr·ª±c ti·∫øp v√†o database
        /// </summary>
        [HttpPost("stream")]
        [DisableRequestSizeLimit]
        [RequestFormLimits(ValueLengthLimit = int.MaxValue, MultipartBodyLengthLimit = long.MaxValue)]
        public async Task<IActionResult> StreamImport()
        {
            try
            {
                _logger.LogInformation("üöÄ [STREAM_IMPORT] Starting streaming upload");

                if (!MultipartRequestHelper.IsMultipartContentType(Request.ContentType))
                {
                    return BadRequest("Request must be multipart/form-data");
                }

                var boundary = MultipartRequestHelper.GetBoundary(
                    MediaTypeHeaderValue.Parse(Request.ContentType),
                    70);

                var reader = new MultipartReader(boundary, HttpContext.Request.Body);
                var section = await reader.ReadNextSectionAsync();

                while (section != null)
                {
                    var hasContentDispositionHeader = ContentDispositionHeaderValue.TryParse(
                        section.ContentDisposition, out var contentDisposition);

                    if (hasContentDispositionHeader &&
                        contentDisposition.DispositionType.Equals("form-data") &&
                        !string.IsNullOrEmpty(contentDisposition.FileName.Value))
                    {
                        var fileName = contentDisposition.FileName.Value.Trim('"');
                        var dataType = _directImportService.DetectDataTypeFromFileName(fileName);

                        _logger.LogInformation("üìÇ [STREAM_IMPORT] Processing file: {FileName}, Type: {DataType}",
                            fileName, dataType);

                        // Stream tr·ª±c ti·∫øp v√†o database
                        var result = await _directImportService.StreamImportAsync(
                            section.Body, fileName, dataType);

                        return Ok(result);
                    }

                    section = await reader.ReadNextSectionAsync();
                }

                return BadRequest("No file found in request");
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [STREAM_IMPORT] Stream import error");
                return StatusCode(500, new
                {
                    success = false,
                    error = ex.Message,
                    type = "STREAM_IMPORT_ERROR"
                });
            }
        }

        /// <summary>
        /// üÜî T·∫°o session cho chunked upload
        /// </summary>
        [HttpPost("create-session")]
        public async Task<IActionResult> CreateUploadSession([FromBody] CreateSessionRequest request)
        {
            try
            {
                var sessionId = Guid.NewGuid().ToString();

                // Store session info (c√≥ th·ªÉ d√πng Redis ho·∫∑c database)
                var sessionInfo = new UploadSession
                {
                    SessionId = sessionId,
                    FileName = request.FileName,
                    FileSize = request.FileSize,
                    TotalChunks = request.TotalChunks,
                    DataType = request.DataType,
                    CreatedAt = DateTime.UtcNow,
                    UploadedChunks = new List<int>()
                };

                // L∆∞u session v√†o cache/database
                await _directImportService.CreateUploadSessionAsync(sessionInfo);

                _logger.LogInformation("üÜî [CREATE_SESSION] Created session {SessionId} for file {FileName}",
                    sessionId, request.FileName);

                return Ok(new { sessionId, success = true });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [CREATE_SESSION] Error creating upload session");
                return StatusCode(500, new { success = false, error = ex.Message });
            }
        }

        /// <summary>
        /// üì§ Upload chunk
        /// </summary>
        [HttpPost("upload-chunk")]
        [DisableRequestSizeLimit]
        public async Task<IActionResult> UploadChunk([FromForm] UploadChunkRequest request)
        {
            try
            {
                var result = await _directImportService.UploadChunkAsync(
                    request.SessionId,
                    request.ChunkIndex,
                    request.Chunk);

                return Ok(result);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [UPLOAD_CHUNK] Error uploading chunk {ChunkIndex} for session {SessionId}",
                    request.ChunkIndex, request.SessionId);
                return StatusCode(500, new { success = false, error = ex.Message });
            }
        }

        /// <summary>
        /// ‚úÖ Finalize chunked upload v√† process file
        /// </summary>
        [HttpPost("finalize/{sessionId}")]
        public async Task<IActionResult> FinalizeUpload(string sessionId)
        {
            try
            {
                var result = await _directImportService.FinalizeUploadAsync(sessionId);
                return Ok(result);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [FINALIZE_UPLOAD] Error finalizing upload for session {SessionId}", sessionId);
                return StatusCode(500, new { success = false, error = ex.Message });
            }
        }

        /// <summary>
        /// üìä Get upload info (for resume functionality)
        /// </summary>
        [HttpGet("upload-info/{sessionId}")]
        public async Task<IActionResult> GetUploadInfo(string sessionId)
        {
            try
            {
                var info = await _directImportService.GetUploadInfoAsync(sessionId);
                return Ok(info);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [UPLOAD_INFO] Error getting upload info for session {SessionId}", sessionId);
                return StatusCode(500, new { success = false, error = ex.Message });
            }
        }

        /// <summary>
        /// üö´ Cancel upload session
        /// </summary>
        [HttpDelete("cancel/{sessionId}")]
        public async Task<IActionResult> CancelUpload(string sessionId)
        {
            try
            {
                await _directImportService.CancelUploadAsync(sessionId);
                return Ok(new { success = true, message = "Upload cancelled" });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [CANCEL_UPLOAD] Error cancelling upload for session {SessionId}", sessionId);
                return StatusCode(500, new { success = false, error = ex.Message });
            }
        }

        /// <summary>
        /// üîÑ PARALLEL CHUNKED UPLOAD - X·ª≠ l√Ω nhi·ªÅu chunks song song
        /// </summary>
        [HttpPost("parallel")]
        [DisableRequestSizeLimit]
        public async Task<IActionResult> ParallelImport(IFormFile file, [FromQuery] int chunkSize = 50000)
        {
            try
            {
                var dataType = _directImportService.DetectDataTypeFromFileName(file.FileName);

                var result = await _directImportService.ParallelImportAsync(
                    file.OpenReadStream(),
                    file.FileName,
                    dataType,
                    chunkSize);

                return Ok(result);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [PARALLEL_IMPORT] Error in parallel import");
                return StatusCode(500, new { success = false, error = ex.Message });
            }
        }

        /// <summary>
        /// Ki·ªÉm tra d·ªØ li·ªáu GL02 - CRTDTM parsing validation
        /// </summary>
        [HttpGet("gl02/validate")]
        public async Task<ActionResult> ValidateGL02Data()
        {
            try
            {
                var validationResult = await _directImportService.ValidateGL02DataAsync();
                return Ok(validationResult);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [GL02_VALIDATE] Error validating GL02 data");
                return StatusCode(500, new { success = false, error = ex.Message });
            }
        }

        /// <summary>
        /// Check GL01 table indexes - Debug performance issues
        /// </summary>
        [HttpGet("debug/gl01-indexes")]
        public async Task<ActionResult> CheckGL01Indexes()
        {
            try
            {
                var sql = @"
                    SELECT
                        i.name as IndexName,
                        i.type_desc as IndexType,
                        i.is_unique as IsUnique,
                        i.is_primary_key as IsPrimaryKey,
                        STRING_AGG(c.name, ', ') as Columns
                    FROM sys.indexes i
                    JOIN sys.index_columns ic ON i.object_id = ic.object_id AND i.index_id = ic.index_id
                    JOIN sys.columns c ON ic.object_id = c.object_id AND ic.column_id = c.column_id
                    WHERE i.object_id = OBJECT_ID('GL01')
                    GROUP BY i.name, i.type_desc, i.is_unique, i.is_primary_key, i.index_id
                    ORDER BY i.index_id;";

                var connection = _context.Database.GetDbConnection();
                await connection.OpenAsync();

                using var command = connection.CreateCommand();
                command.CommandText = sql;

                var indexes = new List<object>();
                using var reader = await command.ExecuteReaderAsync();

                while (await reader.ReadAsync())
                {
                    indexes.Add(new
                    {
                        IndexName = reader["IndexName"]?.ToString(),
                        IndexType = reader["IndexType"]?.ToString(),
                        IsUnique = reader["IsUnique"],
                        IsPrimaryKey = reader["IsPrimaryKey"],
                        Columns = reader["Columns"]?.ToString()
                    });
                }

                return Ok(new
                {
                    success = true,
                    indexCount = indexes.Count,
                    indexes = indexes
                });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [DEBUG] Error checking GL01 indexes");
                return StatusCode(500, new { success = false, error = ex.Message });
            }
        }

        /// <summary>
        /// Disable columnstore index for bulk insert performance
        /// </summary>
        [HttpPost("debug/disable-columnstore")]
        public async Task<ActionResult> DisableColumnstoreIndex()
        {
            try
            {
                var connection = _context.Database.GetDbConnection();
                await connection.OpenAsync();

                using var command = connection.CreateCommand();
                command.CommandText = "DROP INDEX NCCI_GL01_Analytics ON GL01;";

                await command.ExecuteNonQueryAsync();

                _logger.LogInformation("üîß [DEBUG] Disabled columnstore index NCCI_GL01_Analytics");

                return Ok(new
                {
                    success = true,
                    message = "Columnstore index disabled for bulk insert performance",
                    warning = "Remember to re-enable after bulk import!"
                });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [DEBUG] Error disabling columnstore index");
                return StatusCode(500, new { success = false, error = ex.Message });
            }
        }

        /// <summary>
        /// Re-enable columnstore index after bulk insert
        /// </summary>
        [HttpPost("debug/enable-columnstore")]
        public async Task<ActionResult> EnableColumnstoreIndex()
        {
            try
            {
                var connection = _context.Database.GetDbConnection();
                await connection.OpenAsync();

                using var command = connection.CreateCommand();
                command.CommandText = @"
                    CREATE NONCLUSTERED COLUMNSTORE INDEX NCCI_GL01_Analytics
                    ON GL01 (
                        NGAY_DL, STS, NGAY_GD, NGUOI_TAO, DYSEQ, TR_TYPE, DT_SEQ, TAI_KHOAN, TEN_TK,
                        SO_TIEN_GD, POST_BR, LOAI_TIEN, DR_CR, MA_KH, TEN_KH, CCA_USRID, TR_EX_RT,
                        REMARK, BUS_CODE, UNIT_BUS_CODE, TR_CODE, TR_NAME, REFERENCE, VALUE_DATE,
                        DEPT_CODE, TR_TIME, COMFIRM, TRDT_TIME, CREATED_DATE, UPDATED_DATE, FILE_NAME
                    );";

                await command.ExecuteNonQueryAsync();

                _logger.LogInformation("üîß [DEBUG] Re-enabled columnstore index NCCI_GL01_Analytics");

                return Ok(new
                {
                    success = true,
                    message = "Columnstore index re-enabled for analytics performance"
                });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [DEBUG] Error enabling columnstore index");
                return StatusCode(500, new { success = false, error = ex.Message });
            }
        }

        /// <summary>
        /// üéØ OPTIMIZED GL01 BULK IMPORT - Using SQL Server bulk optimization hints
        /// Faster alternative to dropping/recreating columnstore index
        /// </summary>
        [HttpPost("optimized-gl01")]
        [DisableRequestSizeLimit]
        public async Task<ActionResult<object>> OptimizedGL01Import(
            IFormFile file,
            [FromQuery] string? statementDate = null)
        {
            try
            {
                if (file == null || file.Length == 0)
                {
                    return BadRequest("File kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng");
                }

                // Detect data type
                var dataType = _directImportService.DetectDataTypeFromFileName(file.FileName);
                if (dataType != "GL01")
                {
                    return BadRequest($"File kh√¥ng ph·∫£i GL01. Detected type: {dataType}");
                }

                var fileSizeMB = file.Length / 1024.0 / 1024.0;
                _logger.LogInformation("üéØ [OPTIMIZED_GL01] Starting optimized bulk import: {FileName}, Size: {FileSize}MB",
                    file.FileName, fileSizeMB);

                var startTime = DateTime.Now;

                // OPTIMIZATION 1: Disable auto-update statistics during bulk import
                await ExecuteOptimizationCommand("ALTER INDEX ALL ON GL01 SET (STATISTICS_NORECOMPUTE = ON);");

                // OPTIMIZATION 2: Set bulk import options
                await ExecuteOptimizationCommand("ALTER DATABASE TinhKhoanDB SET AUTO_UPDATE_STATISTICS OFF;");

                // Perform the import with optimized settings
                var result = await _directImportService.ImportSmartDirectAsync(file, statementDate);

                // OPTIMIZATION 3: Re-enable statistics (in background)
                _ = Task.Run(async () =>
                {
                    await Task.Delay(1000); // Wait for import to complete
                    await ExecuteOptimizationCommand("ALTER DATABASE TinhKhoanDB SET AUTO_UPDATE_STATISTICS ON;");
                    await ExecuteOptimizationCommand("ALTER INDEX ALL ON GL01 SET (STATISTICS_NORECOMPUTE = OFF);");
                    await ExecuteOptimizationCommand("UPDATE STATISTICS GL01;");
                });

                var endTime = DateTime.Now;
                var duration = endTime - startTime;

                if (result.Success)
                {
                    var response = new
                    {
                        Success = result.Success,
                        FileName = result.FileName,
                        DataType = result.DataType,
                        TargetTable = result.TargetTable,
                        FileSizeBytes = result.FileSizeBytes,
                        FileSizeMB = fileSizeMB,
                        ProcessedRecords = result.ProcessedRecords,
                        ErrorRecords = result.ErrorRecords,
                        NgayDL = result.NgayDL,
                        BatchId = result.BatchId,
                        ImportedDataRecordId = result.ImportedDataRecordId,
                        StartTime = result.StartTime,
                        EndTime = result.EndTime,
                        Duration = result.Duration,
                        RecordsPerSecond = result.RecordsPerSecond,
                        MBPerSecond = result.MBPerSecond,

                        OptimizationInfo = new
                        {
                            Method = "SQL Server Bulk Optimization Hints",
                            StatisticsDisabled = true,
                            ColumnstoreIntact = true,
                            Note = "Statistics re-enabled in background"
                        }
                    };

                    _logger.LogInformation("‚úÖ [OPTIMIZED_GL01] Import completed: {Records} records in {Duration}s",
                        result.ProcessedRecords, duration.TotalSeconds);

                    return Ok(response);
                }
                else
                {
                    return BadRequest(result);
                }
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå [OPTIMIZED_GL01] Error in optimized import");
                return StatusCode(500, new { Success = false, Error = ex.Message });
            }
        }

        /// <summary>
        /// Helper method to execute optimization commands
        /// </summary>
        private async Task ExecuteOptimizationCommand(string sql)
        {
            try
            {
                var connection = _context.Database.GetDbConnection();
                if (connection.State != System.Data.ConnectionState.Open)
                    await connection.OpenAsync();

                using var command = connection.CreateCommand();
                command.CommandText = sql;
                await command.ExecuteNonQueryAsync();
            }
            catch (Exception ex)
            {
                _logger.LogWarning(ex, "‚ö†Ô∏è [OPTIMIZATION] Failed to execute: {SQL}", sql);
            }
        }

        /// <summary>
        /// Internal method to check GL01 indexes
        /// </summary>
        private async Task<List<dynamic>> CheckGL01IndexesInternal()
        {
            var sql = @"
                SELECT
                    i.name as IndexName,
                    i.type_desc as IndexType,
                    i.is_unique as IsUnique,
                    i.is_primary_key as IsPrimaryKey,
                    STRING_AGG(c.name, ', ') as Columns
                FROM sys.indexes i
                JOIN sys.index_columns ic ON i.object_id = ic.object_id AND i.index_id = ic.index_id
                JOIN sys.columns c ON ic.object_id = c.object_id AND ic.column_id = c.column_id
                WHERE i.object_id = OBJECT_ID('GL01')
                GROUP BY i.name, i.type_desc, i.is_unique, i.is_primary_key, i.index_id
                ORDER BY i.index_id;";

            var connection = _context.Database.GetDbConnection();
            await connection.OpenAsync();

            using var command = connection.CreateCommand();
            command.CommandText = sql;

            var indexes = new List<dynamic>();
            using var reader = await command.ExecuteReaderAsync();

            while (await reader.ReadAsync())
            {
                indexes.Add(new
                {
                    IndexName = reader["IndexName"]?.ToString(),
                    IndexType = reader["IndexType"]?.ToString(),
                    IsUnique = reader["IsUnique"],
                    IsPrimaryKey = reader["IsPrimaryKey"],
                    Columns = reader["Columns"]?.ToString()
                });
            }

            return indexes;
        }

        /// <summary>
        /// Internal method to disable columnstore index
        /// </summary>
        private async Task DisableColumnstoreIndexInternal()
        {
            var connection = _context.Database.GetDbConnection();
            if (connection.State != System.Data.ConnectionState.Open)
                await connection.OpenAsync();

            using var command = connection.CreateCommand();
            command.CommandText = "DROP INDEX NCCI_GL01_Analytics ON GL01;";

            await command.ExecuteNonQueryAsync();
        }

        /// <summary>
        /// Internal method to enable columnstore index
        /// </summary>
        private async Task EnableColumnstoreIndexInternal()
        {
            var connection = _context.Database.GetDbConnection();
            if (connection.State != System.Data.ConnectionState.Open)
                await connection.OpenAsync();

            using var command = connection.CreateCommand();
            command.CommandText = @"
                CREATE NONCLUSTERED COLUMNSTORE INDEX NCCI_GL01_Analytics
                ON GL01 (
                    NGAY_DL, STS, NGAY_GD, NGUOI_TAO, DYSEQ, TR_TYPE, DT_SEQ, TAI_KHOAN, TEN_TK,
                    SO_TIEN_GD, POST_BR, LOAI_TIEN, DR_CR, MA_KH, TEN_KH, CCA_USRID, TR_EX_RT,
                    REMARK, BUS_CODE, UNIT_BUS_CODE, TR_CODE, TR_NAME, REFERENCE, VALUE_DATE,
                    DEPT_CODE, TR_TIME, COMFIRM, TRDT_TIME, CREATED_DATE, UPDATED_DATE, FILE_NAME
                );";

            await command.ExecuteNonQueryAsync();
        }

        /// <summary>
        /// LN03 Direct Import - Chuy√™n bi·ªát cho Bad debt data v·ªõi 20 c·ªôt
        /// Lu√¥n import tr·ª±c ti·∫øp v√†o b·∫£ng d·ªØ li·ªáu theo c·∫•u h√¨nh AlwaysDirectImport
        /// </summary>
        /// <param name="file">File LN03 CSV v·ªõi 20 c·ªôt (17 c√≥ header + 3 kh√¥ng header)</param>
        /// <param name="statementDate">Ng√†y b√°o c√°o (optional)</param>
        /// <returns>K·∫øt qu·∫£ import v·ªõi th√¥ng tin chi ti·∫øt v·ªÅ LN03 direct import</returns>
        [HttpPost("ln03-direct")]
        [DisableRequestSizeLimit]
        public async Task<ActionResult<object>> LN03DirectImport(
            IFormFile file,
            [FromQuery] string? statementDate = null)
        {
            try
            {
                if (file == null || file.Length == 0)
                {
                    return BadRequest("File LN03 kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng");
                }

                // Validate file l√† LN03
                var dataType = _directImportService.DetectDataTypeFromFileName(file.FileName);
                if (dataType != "LN03")
                {
                    return BadRequest($"File kh√¥ng ph·∫£i LN03. Detected type: {dataType}. Endpoint n√†y ch·ªâ d√†nh ri√™ng cho LN03.");
                }

                var fileSizeMB = file.Length / 1024.0 / 1024.0;
                _logger.LogInformation("üöÄ [LN03_DIRECT_API] Starting LN03 direct import: {FileName}, Size: {FileSize}MB",
                    file.FileName, fileSizeMB);

                // ‚úÖ DIRECT IMPORT - Lu√¥n bypass m·ªçi x·ª≠ l√Ω trung gian
                var result = await _directImportService.ImportLN03DirectAsync(file, statementDate);

                if (result.Success)
                {
                    var recordsPerSecond = result.ProcessedRecords / Math.Max(result.Duration.TotalSeconds, 0.001);
                    _logger.LogInformation("‚úÖ [LN03_DIRECT_API] LN03 direct import SUCCESS: {Records} records in {Duration}ms ({Rate:F0} records/sec)",
                        result.ProcessedRecords, result.Duration.TotalMilliseconds, recordsPerSecond);

                    return Ok(new
                    {
                        success = true,
                        message = "LN03 import tr·ª±c ti·∫øp th√†nh c√¥ng",
                        dataType = "LN03",
                        targetTable = "LN03",
                        fileName = result.FileName,
                        processedRecords = result.ProcessedRecords,
                        durationMs = result.Duration.TotalMilliseconds,
                        recordsPerSecond = recordsPerSecond,
                        ngayDL = result.NgayDL,
                        importMode = "DIRECT_IMPORT_ONLY",
                        configurationApplied = "AlwaysDirectImport=true, UseCustomParser=true",
                        result
                    });
                }
                else
                {
                    _logger.LogError("‚ùå [LN03_DIRECT_API] LN03 direct import FAILED: {Error}", result.ErrorMessage);
                    return BadRequest(new
                    {
                        success = false,
                        message = "LN03 import tr·ª±c ti·∫øp th·∫•t b·∫°i",
                        error = result.ErrorMessage,
                        fileName = result.FileName,
                        dataType = "LN03",
                        result
                    });
                }
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "üí• [LN03_DIRECT_API] LN03 direct import EXCEPTION: {FileName}", file?.FileName);
                return StatusCode(500, new
                {
                    success = false,
                    message = "L·ªói h·ªá th·ªëng khi import LN03 tr·ª±c ti·∫øp",
                    error = ex.Message,
                    fileName = file?.FileName ?? "Unknown",
                    dataType = "LN03"
                });
            }
        }
    }
}
