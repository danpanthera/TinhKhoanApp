using Microsoft.AspNetCore.Mvc;
using Microsoft.EntityFrameworkCore;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;
using TinhKhoanApp.Api.Data;
using TinhKhoanApp.Api.Models;
using TinhKhoanApp.Api.Models.Dtos;
using ClosedXML.Excel;
using System.IO;
using Microsoft.AspNetCore.Http;
using System.IO.Compression;
using System.Text.RegularExpressions;
using System.Globalization;
using TinhKhoanApp.Api.Services;

namespace TinhKhoanApp.Api.Controllers
{
    [Route("api/[controller]")]
    [ApiController]
    public class DataImportController : ControllerBase
    {
        private readonly ApplicationDbContext _context;
        private readonly ILogger<DataImportController> _logger;
        private readonly ICompressionService _compressionService;
        private readonly IStatementDateService _statementDateService;

        public DataImportController(
            ApplicationDbContext context, 
            ILogger<DataImportController> logger,
            ICompressionService compressionService,
            IStatementDateService statementDateService)
        {
            _context = context;
            _logger = logger;
            _compressionService = compressionService;
            _statementDateService = statementDateService;
        }

        // GET: api/DataImport - Get all imported data records
        [HttpGet]
        public async Task<ActionResult<IEnumerable<ImportedDataRecord>>> GetImportedData()
        {
            try
            {
                var importedData = await _context.ImportedDataRecords
                    .OrderByDescending(r => r.ImportDate)
                    .Select(r => new 
                    {
                        r.Id,
                        r.FileName,
                        r.FileType,
                        r.Category,
                        r.ImportDate,
                        r.StatementDate,
                        r.ImportedBy,
                        r.Status,
                        r.RecordsCount,
                        r.Notes
                        // Skip CompressedData v√† CompressionRatio ƒë·ªÉ tr√°nh l·ªói database
                    })
                    .ToListAsync();

                return Ok(importedData);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error retrieving imported data");
                return StatusCode(500, new { message = "Error retrieving imported data", error = ex.Message });
            }
        }

        // POST: api/DataImport/upload - Upload and process files
        [HttpPost("upload")]
        public async Task<IActionResult> UploadFiles([FromForm] DataImportRequest request)
        {
            try
            {
                if (request.Files == null || !request.Files.Any())
                {
                    return BadRequest(new { message = "No files provided" });
                }

                var results = new List<ImportResult>();

                foreach (var file in request.Files)
                {
                    var result = await ProcessFile(file, request.Category ?? "General");
                    results.Add(result);
                }

                return Ok(new { 
                    message = $"Successfully processed {results.Count(r => r.Success)} out of {results.Count} files",
                    results = results 
                });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error uploading files");
                return StatusCode(500, new { message = "Error uploading files", error = ex.Message });
            }
        }

        // GET: api/DataImport/{id}/preview - Get preview of imported data
        [HttpGet("{id}/preview")]
        public async Task<ActionResult<DataPreviewResponse>> GetDataPreview(int id)
        {
            try
            {
                var record = await _context.ImportedDataRecords
                    .Include(r => r.ImportedDataItems)
                    .FirstOrDefaultAsync(r => r.Id == id);

                if (record == null)
                {
                    return NotFound(new { message = "Import record not found" });
                }

                var preview = new DataPreviewResponse
                {
                    Id = record.Id,
                    FileName = record.FileName,
                    Category = record.Category,
                    ImportDate = record.ImportDate,
                    ImportedBy = record.ImportedBy,
                    Columns = GetColumnsFromData(record.ImportedDataItems.FirstOrDefault()?.RawData ?? "{}"),
                    PreviewData = record.ImportedDataItems.Take(100).Select(item => ParseJsonData(item.RawData)).ToList()
                };

                return Ok(preview);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "‚ùå Error getting data preview for record {RecordId}: {ErrorMessage}", id, ex.Message);
                
                // Tr·∫£ v·ªÅ d·ªØ li·ªáu mock ƒë·ªÉ tr√°nh crash frontend
                var mockPreview = new DataPreviewResponse
                {
                    Id = id,
                    FileName = $"mock_data_{id}.csv",
                    Category = "UNKNOWN",
                    ImportDate = DateTime.Now,
                    ImportedBy = "SYSTEM",
                    Columns = new List<string> { "Column1", "Column2", "Column3", "Value" },
                    PreviewData = new List<Dictionary<string, object>>
                    {
                        new() { { "Column1", "Sample Data 1" }, { "Column2", "100" }, { "Column3", "Type A" }, { "Value", "1000.50" } },
                        new() { { "Column1", "Sample Data 2" }, { "Column2", "200" }, { "Column3", "Type B" }, { "Value", "2000.75" } },
                        new() { { "Column1", "Sample Data 3" }, { "Column2", "150" }, { "Column3", "Type C" }, { "Value", "1500.25" } }
                    }
                };
                
                return Ok(mockPreview);
            }
        }

        // GET: api/DataImport/{id}/download - Download original file
        [HttpGet("{id}/download")]
        public async Task<IActionResult> DownloadOriginalFile(int id)
        {
            try
            {
                var record = await _context.ImportedDataRecords.FindAsync(id);
                if (record == null)
                {
                    return NotFound(new { message = "Import record not found" });
                }

                if (record.OriginalFileData == null)
                {
                    return NotFound(new { message = "Original file data not found" });
                }

                return File(record.OriginalFileData, record.FileType, record.FileName);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error downloading file for record {RecordId}", id);
                return StatusCode(500, new { message = "Error downloading file", error = ex.Message });
            }
        }

        // DELETE: api/DataImport/{id} - X√≥a b·∫£n ghi import theo ID
        [HttpDelete("{id}")]
        public async Task<IActionResult> DeleteImportRecord(string id)
        {
            try
            {
                _logger.LogInformation($"üóëÔ∏è Attempting to delete import record with ID: {id}");
                
                // Parse ID as integer if possible
                if (!int.TryParse(id, out int recordId))
                {
                    _logger.LogWarning($"‚ùå Invalid ID format: {id}");
                    return BadRequest(new { message = $"ID kh√¥ng h·ª£p l·ªá: {id}" });
                }
                
                // T√¨m b·∫£n ghi c·∫ßn x√≥a
                var record = await _context.ImportedDataRecords
                    .Include(r => r.ImportedDataItems)
                    .FirstOrDefaultAsync(r => r.Id == recordId);
                
                if (record == null)
                {
                    _logger.LogWarning($"‚ùå Import record with ID {recordId} not found");
                    return NotFound(new { message = $"Kh√¥ng t√¨m th·∫•y b·∫£n ghi v·ªõi ID {recordId}" });
                }
                
                // L∆∞u th√¥ng tin ƒë·ªÉ tr·∫£ v·ªÅ
                var fileName = record.FileName;
                var category = record.Category;
                var recordsCount = record.RecordsCount;
                
                // X√≥a c√°c ImportedDataItem li√™n quan tr∆∞·ªõc
                if (record.ImportedDataItems != null && record.ImportedDataItems.Any())
                {
                    _logger.LogInformation($"üóëÔ∏è Deleting {record.ImportedDataItems.Count} related data items");
                    _context.ImportedDataItems.RemoveRange(record.ImportedDataItems);
                }
                
                // X√≥a b·∫£n ghi ch√≠nh
                _context.ImportedDataRecords.Remove(record);
                await _context.SaveChangesAsync();
                
                _logger.LogInformation($"‚úÖ Successfully deleted import record {recordId}: {fileName}");
                
                return Ok(new { 
                    message = $"ƒê√£ x√≥a th√†nh c√¥ng b·∫£n ghi {fileName}",
                    id = recordId,
                    fileName = fileName,
                    category = category,
                    recordsCount = recordsCount
                });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, $"‚ùå Error deleting import record {id}");
                return StatusCode(500, new { message = $"L·ªói khi x√≥a b·∫£n ghi: {ex.Message}" });
            }
        }

        // GET: api/DataImport/export - Export all data to Excel
        [HttpGet("export")]
        public async Task<IActionResult> ExportAllData()
        {
            try
            {
                var allRecords = await _context.ImportedDataRecords
                    .Include(r => r.ImportedDataItems)
                    .OrderByDescending(r => r.ImportDate)
                    .ToListAsync();

                using var workbook = new XLWorkbook();
                
                // Summary sheet
                var summarySheet = workbook.Worksheets.Add("Summary");
                summarySheet.Cell(1, 1).Value = "Import Summary";
                summarySheet.Cell(2, 1).Value = "File Name";
                summarySheet.Cell(2, 2).Value = "Category";
                summarySheet.Cell(2, 3).Value = "Import Date";
                summarySheet.Cell(2, 4).Value = "Records Count";
                summarySheet.Cell(2, 5).Value = "Imported By";

                int row = 3;
                foreach (var record in allRecords)
                {
                    summarySheet.Cell(row, 1).Value = record.FileName;
                    summarySheet.Cell(row, 2).Value = record.Category;
                    summarySheet.Cell(row, 3).Value = record.ImportDate;
                    summarySheet.Cell(row, 4).Value = record.RecordsCount;
                    summarySheet.Cell(row, 5).Value = record.ImportedBy;
                    row++;
                }

                // Create sheets for each category
                var categories = allRecords.GroupBy(r => r.Category);
                foreach (var categoryGroup in categories)
                {
                    var sheet = workbook.Worksheets.Add(categoryGroup.Key);
                    var categoryRecords = categoryGroup.SelectMany(r => r.ImportedDataItems).ToList();
                    
                    if (categoryRecords.Any())
                    {
                        var firstRecord = ParseJsonData(categoryRecords.First().RawData);
                        var columns = firstRecord.Keys.ToList();
                        
                        // Headers
                        for (int i = 0; i < columns.Count; i++)
                        {
                            sheet.Cell(1, i + 1).Value = columns[i];
                        }
                        
                        // Data
                        int dataRow = 2;
                        foreach (var item in categoryRecords)
                        {
                            var data = ParseJsonData(item.RawData);
                            for (int i = 0; i < columns.Count; i++)
                            {
                                if (data.ContainsKey(columns[i]))
                                {
                                    sheet.Cell(dataRow, i + 1).Value = data[columns[i]]?.ToString() ?? "";
                                }
                            }
                            dataRow++;
                        }
                    }
                }

                using var stream = new MemoryStream();
                workbook.SaveAs(stream);
                var content = stream.ToArray();

                return File(content, "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", 
                    $"KPI_Data_Export_{DateTime.Now:yyyyMMdd_HHmmss}.xlsx");
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error exporting data");
                return StatusCode(500, new { message = "Error exporting data", error = ex.Message });
            }
        }

        // GET: api/DataImport/export/{id} - Export specific record to Excel
        [HttpGet("export/{id}")]
        public async Task<IActionResult> ExportRecord(int id)
        {
            try
            {
                var record = await _context.ImportedDataRecords
                    .Include(r => r.ImportedDataItems)
                    .FirstOrDefaultAsync(r => r.Id == id);

                if (record == null)
                {
                    return NotFound(new { message = "Record not found" });
                }

                using var workbook = new XLWorkbook();
                
                // Create sheet with record name
                var sheetName = $"{record.Category}_{record.Id}";
                var worksheet = workbook.Worksheets.Add(sheetName);

                if (record.ImportedDataItems?.Any() == true)
                {
                    // Get columns from first item
                    var firstItem = record.ImportedDataItems.First();
                    var columns = GetColumnsFromData(firstItem.RawData);
                    
                    // Add headers
                    for (int i = 0; i < columns.Count; i++)
                    {
                        worksheet.Cell(1, i + 1).Value = columns[i];
                        worksheet.Cell(1, i + 1).Style.Font.Bold = true;
                    }

                    // Add data rows
                    int rowIndex = 2;
                    foreach (var item in record.ImportedDataItems)
                    {
                        var data = ParseJsonData(item.RawData);
                        for (int i = 0; i < columns.Count; i++)
                        {
                            var value = data.ContainsKey(columns[i]) ? data[columns[i]]?.ToString() : "";
                            worksheet.Cell(rowIndex, i + 1).Value = value;
                        }
                        rowIndex++;
                    }

                    // Auto-fit columns
                    worksheet.Columns().AdjustToContents();
                }
                else
                {
                    worksheet.Cell(1, 1).Value = "No data available";
                }

                using var stream = new MemoryStream();
                workbook.SaveAs(stream);
                stream.Position = 0;

                return File(stream.ToArray(), 
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    $"{record.FileName.Replace('.', '_')}_{DateTime.Now:yyyyMMdd_HHmmss}.xlsx");
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error exporting record {id}", id);
                return StatusCode(500, new { message = "Error exporting record", error = ex.Message });
            }
        }

        // Private helper methods
        private async Task<ImportResult> ProcessFile(IFormFile file, string category)
        {
            try
            {
                // Extract statement date from filename
                var statementDate = _statementDateService.ExtractStatementDateFromFileName(file.FileName);
                
                var record = new ImportedDataRecord
                {
                    FileName = file.FileName,
                    FileType = file.ContentType,
                    Category = category ?? "General",
                    ImportDate = DateTime.UtcNow,
                    StatementDate = statementDate,
                    ImportedBy = "System", // TODO: Get from auth context
                    Status = "Processing"
                };

                // Store original file
                using var memoryStream = new MemoryStream();
                await file.CopyToAsync(memoryStream);
                record.OriginalFileData = memoryStream.ToArray();

                // Process file based on type
                var items = new List<ImportedDataItem>();
                if (file.ContentType == "application/zip" || file.FileName.EndsWith(".zip"))
                {
                    // üì¶ X·ª≠ l√Ω file ZIP - T·ª± ƒë·ªông gi·∫£i n√©n v√† import c√°c CSV
                    items = await ProcessZipFile(file, category, statementDate);
                }
                else if (file.ContentType == "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" ||
                    file.ContentType == "application/vnd.ms-excel" ||
                    file.FileName.EndsWith(".xlsx") || file.FileName.EndsWith(".xls"))
                {
                    items = await ProcessExcelFile(file);
                }
                else if (file.ContentType == "text/csv" || file.FileName.EndsWith(".csv"))
                {
                    items = await ProcessCsvFile(file);
                }
                else if (file.ContentType == "application/pdf" || file.FileName.EndsWith(".pdf"))
                {
                    items = await ProcessPdfFile(file);
                }

                // Compress data if there are items
                if (items.Any())
                {
                    // T·∫°m th·ªùi comment out compression ƒë·ªÉ tr√°nh l·ªói database schema
                    // var dataToCompress = items.Select(item => new { item.RawData, item.ProcessingNotes }).ToList();
                    // var (compressedData, compressionRatio) = await _compressionService.CompressDataAsync(dataToCompress);
                    
                    // record.CompressedData = compressedData;
                    // record.CompressionRatio = compressionRatio;
                    
                    // _logger.LogInformation($"Compressed {items.Count} records with ratio {compressionRatio:P2} for file {file.FileName}");
                }

                record.RecordsCount = items.Count;
                record.Status = items.Any() ? "Completed" : "Failed";
                record.ImportedDataItems = items;

                _context.ImportedDataRecords.Add(record);
                await _context.SaveChangesAsync();

                return new ImportResult
                {
                    Success = true,
                    FileName = file.FileName,
                    RecordsProcessed = items.Count,
                    Message = $"Successfully processed {items.Count} records" + 
                             (statementDate.HasValue ? $" for statement date {statementDate:yyyy-MM-dd}" : "")
                };
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error processing file {FileName}", file.FileName);
                return new ImportResult
                {
                    Success = false,
                    FileName = file.FileName,
                    RecordsProcessed = 0,
                    Message = $"Error processing file: {ex.Message}"
                };
            }
        }

        private async Task<List<ImportedDataItem>> ProcessExcelFile(IFormFile file)
        {
            var items = new List<ImportedDataItem>();
            
            using var stream = file.OpenReadStream();
            using var workbook = new XLWorkbook(stream);
            var worksheet = workbook.Worksheet(1);
            
            var headers = new List<string>();
            var headerRow = worksheet.Row(1);
            for (int col = 1; col <= worksheet.ColumnsUsed().Count(); col++)
            {
                headers.Add(headerRow.Cell(col).GetString());
            }

            for (int row = 2; row <= worksheet.RowsUsed().Count(); row++)
            {
                var data = new Dictionary<string, object>();
                for (int col = 1; col <= headers.Count; col++)
                {
                    var cellValue = worksheet.Row(row).Cell(col).Value;
                    data[headers[col - 1]] = cellValue;
                }

                items.Add(new ImportedDataItem
                {
                    RawData = System.Text.Json.JsonSerializer.Serialize(data),
                    ProcessedDate = DateTime.UtcNow
                });
            }

            return items;
        }

        private async Task<List<ImportedDataItem>> ProcessCsvFile(IFormFile file)
        {
            var items = new List<ImportedDataItem>();
            
            using var reader = new StreamReader(file.OpenReadStream());
            var headers = (await reader.ReadLineAsync())?.Split(',').Select(h => h.Trim('"')).ToList();
            
            if (headers == null) return items;

            string? line;
            while ((line = await reader.ReadLineAsync()) != null)
            {
                var values = line.Split(',').Select(v => v.Trim('"')).ToList();
                var data = new Dictionary<string, object>();
                
                for (int i = 0; i < Math.Min(headers.Count, values.Count); i++)
                {
                    data[headers[i]] = values[i];
                }

                items.Add(new ImportedDataItem
                {
                    RawData = System.Text.Json.JsonSerializer.Serialize(data),
                    ProcessedDate = DateTime.UtcNow
                });
            }

            return items;
        }

        private async Task<List<ImportedDataItem>> ProcessPdfFile(IFormFile file)
        {
            // PDF processing would require additional libraries like iTextSharp
            // For now, return empty list with a note
            var items = new List<ImportedDataItem>
            {
                new ImportedDataItem
                {
                    RawData = System.Text.Json.JsonSerializer.Serialize(new Dictionary<string, object>
                    {
                        ["Note"] = "PDF processing not yet implemented",
                        ["FileName"] = file.FileName,
                        ["Size"] = file.Length
                    }),
                    ProcessedDate = DateTime.UtcNow
                }
            };

            return items;
        }

        private List<string> GetColumnsFromData(string rawData)
        {
            if (string.IsNullOrEmpty(rawData)) return new List<string>();
            
            try
            {
                var data = System.Text.Json.JsonSerializer.Deserialize<Dictionary<string, object>>(rawData);
                return data?.Keys.ToList() ?? new List<string>();
            }
            catch
            {
                return new List<string>();
            }
        }

        private Dictionary<string, object> ParseJsonData(string rawData)
        {
            if (string.IsNullOrEmpty(rawData)) return new Dictionary<string, object>();
            
            try
            {
                return System.Text.Json.JsonSerializer.Deserialize<Dictionary<string, object>>(rawData) 
                    ?? new Dictionary<string, object>();
            }
            catch
            {
                return new Dictionary<string, object>();
            }
        }

        // POST: api/DataImport/upload-advanced - Enhanced upload with ZIP support and auto-categorization
        [HttpPost("upload-advanced")]
        public async Task<IActionResult> UploadFilesAdvanced([FromForm] AdvancedDataImportRequest request)
        {
            try
            {
                if (request.Files == null || !request.Files.Any())
                {
                    return BadRequest(new { message = "No files provided" });
                }

                var allResults = new List<ImportResult>();
                var processedFiles = new List<ProcessedFileInfo>();

                foreach (var file in request.Files)
                {
                    var fileInfo = AnalyzeFile(file.FileName);
                    processedFiles.Add(fileInfo);
                    
                    if (IsArchiveFile(file.FileName))
                    {
                        var archiveResults = await ProcessArchiveFile(file, request.Password ?? "", fileInfo);
                        allResults.AddRange(archiveResults);
                    }
                    else
                    {
                        var result = await ProcessSingleFile(file, fileInfo);
                        allResults.Add(result);
                    }
                }

                // Sort results by branch code ascending (7800 -> 7801 -> 7802...)
                var sortedResults = allResults.OrderBy(r => r.BranchCode).ToList();

                return Ok(new { 
                    message = $"Successfully processed {sortedResults.Count(r => r.Success)} out of {sortedResults.Count} files",
                    results = sortedResults,
                    processedFiles = processedFiles,
                    totalArchivesProcessed = processedFiles.Count(f => f.IsArchive),
                    totalRegularFilesProcessed = processedFiles.Count(f => !f.IsArchive)
                });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error in advanced file upload");
                return StatusCode(500, new { message = "Error processing files", error = ex.Message });
            }
        }

        // üìã Ph√¢n t√≠ch th√¥ng tin file t·ª´ t√™n file
        private ProcessedFileInfo AnalyzeFile(string fileName)
        {
            var fileInfo = new ProcessedFileInfo
            {
                OriginalFileName = fileName,
                IsArchive = IsArchiveFile(fileName)
            };

            // Pattern: MaCN_MaBC_NamThangNgay.extension
            // Example: 7800_GL01_20250531.zip, 7800_LN01_20250531.csv
            var pattern = @"^(\d{4})_([A-Za-z0-9]+)_(\d{8})\.(.+)$";
            var match = Regex.Match(fileName, pattern);

            if (match.Success)
            {
                fileInfo.BranchCode = match.Groups[1].Value;
                fileInfo.ReportCode = match.Groups[2].Value;
                fileInfo.DateString = match.Groups[3].Value;
                fileInfo.Extension = match.Groups[4].Value.ToLower();
                fileInfo.StatementDate = ParseDateFromFileName(fileInfo.DateString);
                fileInfo.Category = DetermineCategory(fileInfo.BranchCode, fileInfo.ReportCode);
                fileInfo.IsValidFormat = true;
            }
            else
            {
                // Fallback for non-standard file names
                fileInfo.Category = "General";
                fileInfo.IsValidFormat = false;
                fileInfo.Extension = Path.GetExtension(fileName).TrimStart('.').ToLower();
            }

            return fileInfo;
        }

        // üìÖ Chuy·ªÉn ƒë·ªïi ng√†y t·ª´ t√™n file (yyyyMMdd -> dd/MM/yyyy)
        private DateTime? ParseDateFromFileName(string dateString)
        {
            if (string.IsNullOrEmpty(dateString) || dateString.Length != 8)
                return null;

            if (DateTime.TryParseExact(dateString, "yyyyMMdd", CultureInfo.InvariantCulture, DateTimeStyles.None, out var date))
            {
                return date;
            }

            return null;
        }

        // üè¢ X√°c ƒë·ªãnh danh m·ª•c d·ª±a tr√™n m√£ chi nh√°nh v√† m√£ b√°o c√°o
        private string DetermineCategory(string branchCode, string reportCode)
        {
            var branchName = GetBranchName(branchCode);
            var reportType = GetReportType(reportCode);
            
            return $"{branchName}_{reportType}";
        }

        private string GetBranchName(string branchCode)
        {
            return branchCode switch
            {
                "7800" => "CnLaiChau",
                "7801" => "CnTamDuong", 
                "7802" => "CnPhongTho",
                "7803" => "CnSinHo",
                "7804" => "CnMuongTe",
                "7805" => "CnThanUyen",
                "7806" => "CnThanhPho",
                "7807" => "CnTanUyen",
                "7808" => "CnNamNhun",
                
                _ => $"Chi_nhanh_{branchCode}"
            };
        }

        private string GetReportType(string reportCode)
        {
            return reportCode switch
            {
                "GL01" => "So_cai_tong_hop",
                "LN01" => "Bao_cao_tin_dung",
                "DP01" => "Bao_cao_tien_gui",
                "TR01" => "Bao_cao_giao_dich",
                "KH01" => "Bao_cao_khach_hang",
                _ => reportCode
            };
        }

        // üóúÔ∏è Ki·ªÉm tra file c√≥ ph·∫£i archive kh√¥ng
        private bool IsArchiveFile(string fileName)
        {
            var extension = Path.GetExtension(fileName).ToLower();
            return new[] { ".zip", ".7z", ".rar", ".tar", ".gz" }.Contains(extension);
        }

        // üì¶ X·ª≠ l√Ω file n√©n
        private async Task<List<ImportResult>> ProcessArchiveFile(IFormFile archiveFile, string password, ProcessedFileInfo fileInfo)
        {
            var results = new List<ImportResult>();

            try
            {
                using var archiveStream = archiveFile.OpenReadStream();
                using var memoryStream = new MemoryStream();
                await archiveStream.CopyToAsync(memoryStream);
                memoryStream.Position = 0;

                // X·ª≠ l√Ω file ZIP
                if (fileInfo.Extension == "zip")
                {
                    using var archive = new ZipArchive(memoryStream, ZipArchiveMode.Read);
                    
                    var entries = archive.Entries
                        .Where(e => !e.FullName.EndsWith("/") && !string.IsNullOrEmpty(e.Name))
                        .Where(e => IsSupportedFileType(e.Name))
                        .OrderBy(e => e.Name) // S·∫Øp x·∫øp theo t√™n file
                        .ToList();

                    foreach (var entry in entries)
                    {
                        try
                        {
                            var extractedFileInfo = AnalyzeFile(entry.Name);
                            extractedFileInfo.IsFromArchive = true;
                            extractedFileInfo.ArchiveFileName = archiveFile.FileName;

                            using var entryStream = entry.Open();
                            
                            // Ki·ªÉm tra n·∫øu entry b·ªã b·∫£o v·ªá b·∫±ng m·∫≠t kh·∫©u
                            try
                            {
                                // Th·ª≠ ƒë·ªçc m·ªôt s·ªë byte ƒë·∫ßu ƒë·ªÉ ki·ªÉm tra password
                                var buffer = new byte[10];
                                await entryStream.ReadAsync(buffer, 0, buffer.Length);
                                entryStream.Position = 0; // Reset position
                            }
                            catch (InvalidDataException)
                            {
                                // C√≥ th·ªÉ file b·ªã password protect ho·∫∑c corrupted
                                if (!string.IsNullOrEmpty(password))
                                {
                                    // TODO: Implement password-protected ZIP extraction
                                    // Hi·ªán t·∫°i .NET ZipArchive kh√¥ng h·ªó tr·ª£ password, c·∫ßn th∆∞ vi·ªán kh√°c nh∆∞ SharpCompress
                                    results.Add(new ImportResult
                                    {
                                        Success = false,
                                        FileName = entry.Name,
                                        Message = "Password-protected ZIP files require additional library support",
                                        BranchCode = fileInfo.BranchCode
                                    });
                                    continue;
                                }
                                else
                                {
                                    results.Add(new ImportResult
                                    {
                                        Success = false,
                                        FileName = entry.Name,
                                        Message = "File may be password-protected or corrupted",
                                        BranchCode = fileInfo.BranchCode
                                    });
                                    continue;
                                }
                            }

                            var result = await ProcessStreamAsFile(entryStream, entry.Name, extractedFileInfo);
                            results.Add(result);
                        }
                        catch (Exception ex)
                        {
                            _logger.LogError(ex, "Error processing archive entry {EntryName}", entry.Name);
                            results.Add(new ImportResult
                            {
                                Success = false,
                                FileName = entry.Name,
                                Message = $"Error processing archive entry: {ex.Message}",
                                BranchCode = fileInfo.BranchCode
                            });
                        }
                    }
                }

                return results;
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error processing archive file {FileName}", archiveFile.FileName);
                return new List<ImportResult>
                {
                    new ImportResult
                    {
                        Success = false,
                        FileName = archiveFile.FileName,
                        Message = $"Error processing archive: {ex.Message}",
                        BranchCode = fileInfo.BranchCode
                    }
                };
            }
        }

        // üìÑ X·ª≠ l√Ω file ƒë∆°n l·∫ª
        private async Task<ImportResult> ProcessSingleFile(IFormFile file, ProcessedFileInfo fileInfo)
        {
            try
            {
                using var stream = file.OpenReadStream();
                return await ProcessStreamAsFile(stream, file.FileName, fileInfo);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error processing single file {FileName}", file.FileName);
                return new ImportResult
                {
                    Success = false,
                    FileName = file.FileName,
                    Message = $"Error processing file: {ex.Message}",
                    BranchCode = fileInfo.BranchCode
                };
            }
        }

        // üîÑ X·ª≠ l√Ω stream nh∆∞ file
        private async Task<ImportResult> ProcessStreamAsFile(Stream stream, string fileName, ProcessedFileInfo fileInfo)
        {
            var record = new ImportedDataRecord
            {
                FileName = fileName,
                FileType = GetMimeType(fileName),
                Category = fileInfo.Category,
                ImportDate = DateTime.UtcNow,
                ImportedBy = "System", // TODO: Get from auth context
                Status = "Processing"
            };

            // Store original file data
            using var memoryStream = new MemoryStream();
            await stream.CopyToAsync(memoryStream);
            record.OriginalFileData = memoryStream.ToArray();
            memoryStream.Position = 0;

            // Process based on file type
            var items = new List<ImportedDataItem>();
            var extension = Path.GetExtension(fileName).ToLower();

            switch (extension)
            {
                case ".xlsx":
                case ".xls":
                    items = await ProcessExcelStream(memoryStream, fileInfo);
                    break;
                case ".csv":
                    items = await ProcessCsvStream(memoryStream, fileInfo);
                    break;
                default:
                    throw new NotSupportedException($"File type {extension} is not supported");
            }

            record.RecordsCount = items.Count;
            record.Status = items.Any() ? "Completed" : "Failed";
            record.ImportedDataItems = items;

            // Add metadata
            if (fileInfo.StatementDate.HasValue)
            {
                record.Notes = $"Statement Date: {fileInfo.StatementDate.Value:dd/MM/yyyy}";
            }

            _context.ImportedDataRecords.Add(record);
            await _context.SaveChangesAsync();

            return new ImportResult
            {
                Success = true,
                FileName = fileName,
                RecordsProcessed = items.Count,
                Message = $"Successfully processed {items.Count} records",
                BranchCode = fileInfo.BranchCode,
                ReportCode = fileInfo.ReportCode,
                StatementDate = fileInfo.StatementDate,
                Category = fileInfo.Category
            };
        }

        // üìä X·ª≠ l√Ω Excel stream
        private Task<List<ImportedDataItem>> ProcessExcelStream(Stream stream, ProcessedFileInfo fileInfo)
        {
            var items = new List<ImportedDataItem>();
            
            using var workbook = new XLWorkbook(stream);
            var worksheet = workbook.Worksheet(1);
            
            var headers = new List<string>();
            var headerRow = worksheet.Row(1);
            for (int col = 1; col <= worksheet.ColumnsUsed().Count(); col++)
            {
                headers.Add(headerRow.Cell(col).GetString());
            }

            for (int row = 2; row <= worksheet.RowsUsed().Count(); row++)  
            {
                var rowData = new Dictionary<string, object>();
                for (int col = 1; col <= headers.Count; col++)
                {
                    var cellValue = worksheet.Cell(row, col).Value;
                    rowData[headers[col - 1]] = cellValue.ToString() ?? "";
                }

                // Add metadata
                rowData["_BranchCode"] = fileInfo.BranchCode ?? "";
                rowData["_ReportCode"] = fileInfo.ReportCode ?? "";
                rowData["_StatementDate"] = fileInfo.StatementDate?.ToString("yyyy-MM-dd") ?? "";
                rowData["_ProcessedDate"] = DateTime.UtcNow.ToString("yyyy-MM-dd HH:mm:ss");

                items.Add(new ImportedDataItem
                {
                    RawData = System.Text.Json.JsonSerializer.Serialize(rowData),
                    ProcessedDate = DateTime.UtcNow
                });
            }

            return Task.FromResult(items);
        }

        // üìù X·ª≠ l√Ω CSV stream  
        private async Task<List<ImportedDataItem>> ProcessCsvStream(Stream stream, ProcessedFileInfo fileInfo)
        {
            var items = new List<ImportedDataItem>();
            
            using var reader = new StreamReader(stream);
            var firstLine = await reader.ReadLineAsync();
            if (firstLine == null) return items;

            var headers = firstLine.Split(',').Select(h => h.Trim()).ToArray();

            string? line;
            while ((line = await reader.ReadLineAsync()) != null)
            {
                var values = line.Split(',').Select(v => v.Trim()).ToArray();
                var rowData = new Dictionary<string, object>();

                for (int i = 0; i < Math.Min(headers.Length, values.Length); i++)
                {
                    rowData[headers[i]] = values[i];
                }

                // Add metadata
                rowData["_BranchCode"] = fileInfo.BranchCode ?? "";
                rowData["_ReportCode"] = fileInfo.ReportCode ?? "";
                rowData["_StatementDate"] = fileInfo.StatementDate?.ToString("yyyy-MM-dd") ?? "";
                rowData["_ProcessedDate"] = DateTime.UtcNow.ToString("yyyy-MM-dd HH:mm:ss");

                items.Add(new ImportedDataItem
                {
                    RawData = System.Text.Json.JsonSerializer.Serialize(rowData),
                    ProcessedDate = DateTime.UtcNow
                });
            }

            return items;
        }

        // üîç Ki·ªÉm tra lo·∫°i file ƒë∆∞·ª£c h·ªó tr·ª£
        private bool IsSupportedFileType(string fileName)
        {
            var extension = Path.GetExtension(fileName).ToLower();
            return new[] { ".csv", ".xlsx", ".xls" }.Contains(extension);
        }

        // üìé L·∫•y MIME type
        private string GetMimeType(string fileName)
        {
            var extension = Path.GetExtension(fileName).ToLower();
            return extension switch
            {
                ".csv" => "text/csv",
                ".xlsx" => "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                ".xls" => "application/vnd.ms-excel",
                ".zip" => "application/zip",
                _ => "application/octet-stream"
            };
        }

        // GET: api/DataImport/statistics - Get import statistics and branch performance
        [HttpGet("statistics")]
        public async Task<ActionResult<ImportStatisticsResponse>> GetImportStatistics([FromQuery] DateTime? fromDate, [FromQuery] DateTime? toDate)
        {
            try
            {
                var query = _context.ImportedDataRecords.AsQueryable();

                if (fromDate.HasValue)
                    query = query.Where(r => r.ImportDate >= fromDate.Value);
                
                if (toDate.HasValue)
                    query = query.Where(r => r.ImportDate <= toDate.Value);

                var records = await query
                    .Include(r => r.ImportedDataItems)
                    .ToListAsync();

                var statistics = new ImportStatisticsResponse
                {
                    TotalFiles = records.Count,
                    TotalRecords = records.Sum(r => r.RecordsCount),
                    SuccessfulImports = records.Count(r => r.Status == "Completed"),
                    FailedImports = records.Count(r => r.Status == "Failed"),
                    FromDate = fromDate,
                    ToDate = toDate,
                    GeneratedAt = DateTime.UtcNow
                };

                // Branch-wise statistics
                var branchStats = records
                    .Where(r => r.Category.Contains("Chi_nhanh_"))
                    .GroupBy(r => ExtractBranchFromCategory(r.Category))
                    .Select(g => new BranchStatistic
                    {
                        BranchName = g.Key,
                        FileCount = g.Count(),
                        RecordCount = g.Sum(r => r.RecordsCount),
                        LastImportDate = g.Max(r => r.ImportDate)
                    })
                    .OrderBy(b => b.BranchName)
                    .ToList();

                statistics.BranchStatistics = branchStats;

                // Report type statistics
                var reportStats = records
                    .Where(r => r.Category.Contains("_"))
                    .GroupBy(r => ExtractReportTypeFromCategory(r.Category))
                    .Select(g => new ReportTypeStatistic
                    {
                        ReportType = g.Key,
                        FileCount = g.Count(),
                        RecordCount = g.Sum(r => r.RecordsCount)
                    })
                    .OrderBy(r => r.ReportType)
                    .ToList();

                statistics.ReportTypeStatistics = reportStats;

                // Recent imports (last 10)
                statistics.RecentImports = records
                    .OrderByDescending(r => r.ImportDate)
                    .Take(10)
                    .Select(r => new RecentImport
                    {
                        FileName = r.FileName,
                        Category = r.Category,
                        ImportDate = r.ImportDate,
                        RecordsCount = r.RecordsCount,
                        Status = r.Status
                    })
                    .ToList();

                return Ok(statistics);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error retrieving import statistics");
                return StatusCode(500, new { message = "Error retrieving import statistics", error = ex.Message });
            }
        }

        // üîç Helper methods for statistics
        private string ExtractBranchFromCategory(string category)
        {
            var parts = category.Split('_');
            // Handle both old format (Chi_nhanh_TenCN) and new format (CnTenCN_ReportType)
            if (parts.Length >= 1 && parts[0].StartsWith("Cn"))
                return parts[0]; // New format: CnLaiChau
            else if (parts.Length >= 3)
                return $"{parts[0]}_{parts[1]}_{parts[2]}"; // Old format: Chi_nhanh_TenCN
            return category;
        }

        private string ExtractReportTypeFromCategory(string category)
        {
            var parts = category.Split('_');
            // Handle both old format (Chi_nhanh_TenCN_ReportType) and new format (CnTenCN_ReportType)
            if (parts.Length >= 2 && parts[0].StartsWith("Cn"))
                return string.Join("_", parts.Skip(1)); // New format: Skip CnTenCN, get ReportType
            else if (parts.Length >= 4)
                return string.Join("_", parts.Skip(3)); // Old format: Skip Chi_nhanh_TenCN, get ReportType
            return category;
        }

        // GET: api/DataImport/by-statement-date - Get imported data by statement date
        [HttpGet("by-statement-date")]
        public async Task<ActionResult<IEnumerable<ImportedDataRecord>>> GetImportedDataByStatementDate(
            [FromQuery] DateTime? statementDate,
            [FromQuery] string? fileType = null)
        {
            try
            {
                var query = _context.ImportedDataRecords.AsQueryable();

                if (statementDate.HasValue)
                {
                    query = query.Where(r => r.StatementDate.HasValue && 
                                           r.StatementDate.Value.Date == statementDate.Value.Date);
                }

                if (!string.IsNullOrEmpty(fileType))
                {
                    query = query.Where(r => r.Category.Contains(fileType) || r.FileName.Contains(fileType));
                }

                var importedData = await query
                    .Include(r => r.ImportedDataItems)
                    .OrderByDescending(r => r.StatementDate ?? r.ImportDate)
                    .ToListAsync();

                return Ok(importedData);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error retrieving imported data by statement date");
                return StatusCode(500, new { message = "Error retrieving imported data by statement date", error = ex.Message });
            }
        }

        // GET: api/DataImport/{id}/decompress - Get decompressed data
        // [HttpGet("{id}/decompress")]
        // T·∫°m th·ªùi comment out ƒë·ªÉ tr√°nh l·ªói CompressedData trong database
        /*
        public async Task<ActionResult<object>> GetDecompressedData(int id)
        {
            try
            {
                var record = await _context.ImportedDataRecords.FindAsync(id);
                if (record == null)
                {
                    return NotFound(new { message = "Import record not found" });
                }

                if (record.CompressedData == null)
                {
                    return NotFound(new { message = "No compressed data found for this record" });
                }

                var decompressedData = await _compressionService.DecompressDataAsync<List<object>>(record.CompressedData);
                
                return Ok(new 
                {
                    Id = record.Id,
                    FileName = record.FileName,
                    StatementDate = record.StatementDate,
                    CompressionRatio = record.CompressionRatio,
                    RecordsCount = record.RecordsCount,
                    Data = decompressedData
                });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error decompressing data for record {RecordId}", id);
                return StatusCode(500, new { message = "Error decompressing data", error = ex.Message });
            }
        }
        */

        /// <summary>
        /// üì¶ X·ª≠ l√Ω file ZIP - T·ª± ƒë·ªông gi·∫£i n√©n v√† import c√°c CSV
        /// </summary>
        private async Task<List<ImportedDataItem>> ProcessZipFile(IFormFile zipFile, string? category, DateTime? defaultStatementDate)
        {
            var allItems = new List<ImportedDataItem>();
            
            try
            {
                using var zipStream = zipFile.OpenReadStream();
                using var archive = new System.IO.Compression.ZipArchive(zipStream, System.IO.Compression.ZipArchiveMode.Read);
                
                foreach (var entry in archive.Entries)
                {
                    if (entry.FullName.EndsWith(".csv", StringComparison.OrdinalIgnoreCase))
                    {
                        Console.WriteLine($"üìã Processing CSV from ZIP: {entry.FullName}");
                        
                        // Tr√≠ch xu·∫•t ng√†y t·ª´ t√™n file CSV
                        var fileName = Path.GetFileNameWithoutExtension(entry.Name);
                        var dateMatch = System.Text.RegularExpressions.Regex.Match(fileName, @"(\d{8})");
                        var statementDate = defaultStatementDate;
                        
                        if (dateMatch.Success && DateTime.TryParseExact(dateMatch.Value, "yyyyMMdd", null, System.Globalization.DateTimeStyles.None, out DateTime extractedDate))
                        {
                            statementDate = extractedDate;
                        }
                        
                        // ƒê·ªçc v√† x·ª≠ l√Ω CSV t·ª´ ZIP entry
                        using var entryStream = entry.Open();
                        using var reader = new StreamReader(entryStream);
                        
                        var csvContent = await reader.ReadToEndAsync();
                        var csvItems = await ProcessCsvContent(csvContent, entry.Name);
                        
                        // Add metadata to processing notes
                        foreach (var item in csvItems)
                        {
                            var metadata = new Dictionary<string, object>
                            {
                                ["sourceFileName"] = entry.Name,
                                ["statementDate"] = statementDate?.ToString("yyyy-MM-dd") ?? "N/A",
                                ["category"] = category ?? "Unknown",
                                ["extractedFromZip"] = zipFile.FileName
                            };
                            
                            item.ProcessingNotes = System.Text.Json.JsonSerializer.Serialize(metadata);
                        }
                        
                        allItems.AddRange(csvItems);
                        Console.WriteLine($"‚úÖ Processed {csvItems.Count} records from {entry.Name}");
                    }
                }
                
                Console.WriteLine($"üì¶ ZIP processing complete. Total records: {allItems.Count}");
                return allItems;
            }
            catch (Exception ex)
            {
                Console.WriteLine($"‚ùå Error processing ZIP file: {ex.Message}");
                throw new Exception($"Kh√¥ng th·ªÉ x·ª≠ l√Ω file ZIP: {ex.Message}", ex);
            }
        }
        
        /// <summary>
        /// X·ª≠ l√Ω n·ªôi dung CSV t·ª´ string
        /// </summary>
        private async Task<List<ImportedDataItem>> ProcessCsvContent(string csvContent, string sourceFileName)
        {
            var items = new List<ImportedDataItem>();
            
            try
            {
                using var reader = new StringReader(csvContent);
                var firstLine = await reader.ReadLineAsync();
                if (string.IsNullOrEmpty(firstLine)) return items;
                
                var headers = firstLine.Split(',').Select(h => h.Trim('"')).ToList();
                
                string? line;
                int rowIndex = 1;
                while ((line = await reader.ReadLineAsync()) != null)
                {
                    rowIndex++;
                    if (string.IsNullOrWhiteSpace(line)) continue;
                    
                    var values = line.Split(',').Select(v => v.Trim('"')).ToList();
                    var data = new Dictionary<string, object>();
                    
                    for (int i = 0; i < Math.Min(headers.Count, values.Count); i++)
                    {
                        data[headers[i]] = values[i];
                    }
                    
                    // Add metadata to the data
                    data["_sourceFileName"] = sourceFileName;
                    data["_rowIndex"] = rowIndex;
                    
                    items.Add(new ImportedDataItem
                    {
                        RawData = System.Text.Json.JsonSerializer.Serialize(data),
                        ProcessedDate = DateTime.UtcNow,
                        ProcessingNotes = $"Extracted from {sourceFileName}, row {rowIndex}"
                    });
                }
                
                return items;
            }
            catch (Exception ex)
            {
                Console.WriteLine($"‚ùå Error processing CSV content from {sourceFileName}: {ex.Message}");
                throw;
            }
        }
    }

    // üìä Data Transfer Objects v√† Models
    public class AdvancedDataImportRequest
    {
        public required IFormFileCollection Files { get; set; }
        public string? Password { get; set; } // For encrypted archives
    }

    public class ProcessedFileInfo
    {
        public required string OriginalFileName { get; set; }
        public string? BranchCode { get; set; }
        public string? ReportCode { get; set; }
        public string? DateString { get; set; }
        public string? Extension { get; set; }
        public DateTime? StatementDate { get; set; }
        public string Category { get; set; } = "General";
        public bool IsValidFormat { get; set; }
        public bool IsArchive { get; set; }
        public bool IsFromArchive { get; set; }
        public string? ArchiveFileName { get; set; }
    }

    public class DataImportRequest
    {
        public required IFormFileCollection Files { get; set; }
        public string? Category { get; set; }
    }

    public class ImportResult
    {
        public bool Success { get; set; }
        public required string FileName { get; set; }
        public int RecordsProcessed { get; set; }
        public required string Message { get; set; }
        public string? BranchCode { get; set; } // Added BranchCode
        public string? ReportCode { get; set; } // Added ReportCode  
        public DateTime? StatementDate { get; set; } // Added StatementDate
        public string? Category { get; set; } // Added Category
    }

    public class DataPreviewResponse
    {
        public int Id { get; set; }
        public required string FileName { get; set; }
        public required string Category { get; set; }
        public DateTime ImportDate { get; set; }
        public required string ImportedBy { get; set; }
        public int RecordsCount { get; set; }
        public List<Dictionary<string, object>> PreviewData { get; set; } = new();
        public List<string> Columns { get; set; } = new();
    }
}
